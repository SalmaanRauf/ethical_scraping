import sqlite3
import pandas as pd
import time
from datetime import date, datetime
from typing import List, Dict, Any
import os
from functools import wraps

def retry_file_operation(max_retries=3, delay=1):
    """Decorator for retrying file operations with exponential backoff."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except IOError as e:
                    if attempt == max_retries - 1:
                        print(f"❌ File operation failed after {max_retries} attempts: {e}")
                        raise
                    print(f"⚠️  File operation failed (attempt {attempt + 1}/{max_retries}): {e}")
                    time.sleep(delay * (2 ** attempt))  # Exponential backoff
            return None
        return wrapper
    return decorator

class Reporter:
    def __init__(self, db_path='data/research.db'):
        self.db_path = db_path
        self.max_results_per_query = 1000  # Limit results to prevent memory issues
        # Ensure reports directory exists
        os.makedirs('reports', exist_ok=True)

    def _get_paginated_results(self, query: str, params: tuple, page_size: int = 100) -> pd.DataFrame:
        """Get results in pages to prevent memory issues with large datasets."""
        all_results = []
        offset = 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                while True:
                    # Add LIMIT and OFFSET to query
                    paginated_query = f"{query} LIMIT {page_size} OFFSET {offset}"
                    
                    df_page = pd.read_sql_query(paginated_query, conn, params=params)
                    
                    if df_page.empty:
                        break
                    
                    all_results.append(df_page)
                    offset += page_size
                    
                    # Safety check to prevent infinite loops
                    if len(all_results) * page_size > self.max_results_per_query:
                        print(f"⚠️  Reached maximum results limit ({self.max_results_per_query})")
                        break
                
                # Combine all pages
                if all_results:
                    return pd.concat(all_results, ignore_index=True)
                else:
                    return pd.DataFrame()
                    
        except Exception as e:
            print(f"❌ Error in paginated query: {e}")
            return pd.DataFrame()

    def generate_report(self) -> str:
        """
        Queries DB for today's findings and generates a report.
        """
        today_str = date.today().isoformat()
        
        try:
            # Query for findings found today using pagination
            query = """
                SELECT 
                    date_found, company, headline, what_happened, 
                    why_it_matters, consulting_angle, source_url, 
                    event_type, value_usd, source_type
                FROM findings 
                WHERE date_found LIKE ?
                ORDER BY created_at DESC
            """
            
            df = self._get_paginated_results(query, (f"{today_str}%",))
            
            if df.empty:
                report_content = "# Daily Intelligence Report\n\n"
                report_content += f"**Date:** {today_str}\n\n"
                report_content += "## Summary\n\n"
                report_content += "No material updates found today.\n\n"
                report_content += "---\n"
                report_content += "*Report generated by Agentic Account Research System*"
            else:
                # Add Key Person columns as per requirements
                df['Key Person 1 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                df['Key Person 2 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                
                # Rename columns to match final schema
                df.rename(columns={
                    'date_found': 'Date', 
                    'company': 'Company', 
                    'headline': 'Headline', 
                    'what_happened': 'What Happened?', 
                    'why_it_matters': 'Why it Matters', 
                    'consulting_angle': 'Consulting Angle', 
                    'source_url': 'Source 1 (URL)',
                    'event_type': 'Event Type',
                    'value_usd': 'Value (USD)'
                }, inplace=True)
                
                # Reorder columns to match required output schema
                column_order = [
                    'Date', 'Company', 'Headline', 'What Happened?', 
                    'Why it Matters', 'Consulting Angle', 'Source 1 (URL)',
                    'Key Person 1 (URL, Role, Score)', 'Key Person 2 (URL, Role, Score)',
                    'Event Type', 'Value (USD)'
                ]
                
                # Only include columns that exist in the dataframe
                existing_columns = [col for col in column_order if col in df.columns]
                df = df[existing_columns]
                
                # Generate markdown report
                report_content = "# Daily Intelligence Report\n\n"
                report_content += f"**Date:** {today_str}\n\n"
                report_content += f"**Total Events Found:** {len(df)}\n\n"
                report_content += "## Summary\n\n"
                
                # Add summary statistics
                if 'Event Type' in df.columns:
                    event_counts = df['Event Type'].value_counts()
                    report_content += "**Events by Type:**\n"
                    for event_type, count in event_counts.items():
                        report_content += f"- {event_type}: {count}\n"
                    report_content += "\n"
                
                if 'Value (USD)' in df.columns:
                    total_value = df['Value (USD)'].sum()
                    if total_value > 0:
                        report_content += f"**Total Value:** ${total_value:,}\n\n"
                
                report_content += "## Detailed Findings\n\n"
                report_content += df.to_markdown(index=False)
                report_content += "\n\n---\n"
                report_content += "*Report generated by Agentic Account Research System*"

        except Exception as e:
            print(f"❌ Error generating report: {e}")
            report_content = f"# Error Generating Report\n\nError: {e}"

        # Save report to a file with retry logic
        report_filename = f"reports/report-{today_str}.md"
        self._save_report_with_retry(report_filename, report_content)

        return report_content

    @retry_file_operation(max_retries=3, delay=1)
    def _save_report_with_retry(self, filename: str, content: str):
        """Save report with retry logic."""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"✅ Report generated: {filename}")

    def generate_csv_report(self) -> str:
        """
        Generate a CSV version of today's report.
        """
        today_str = date.today().isoformat()
        
        try:
            # Query for findings found today using pagination
            query = """
                SELECT 
                    date_found, company, headline, what_happened, 
                    why_it_matters, consulting_angle, source_url, 
                    event_type, value_usd, source_type
                FROM findings 
                WHERE date_found LIKE ?
                ORDER BY created_at DESC
            """
            
            df = self._get_paginated_results(query, (f"{today_str}%",))
            
            if not df.empty:
                # Add Key Person columns
                df['Key Person 1 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                df['Key Person 2 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                
                # Rename columns
                df.rename(columns={
                    'date_found': 'Date', 
                    'company': 'Company', 
                    'headline': 'Headline', 
                    'what_happened': 'What Happened?', 
                    'why_it_matters': 'Why it Matters', 
                    'consulting_angle': 'Consulting Angle', 
                    'source_url': 'Source 1 (URL)',
                    'event_type': 'Event Type',
                    'value_usd': 'Value (USD)'
                }, inplace=True)
                
                # Save CSV with retry logic
                csv_filename = f"reports/report-{today_str}.csv"
                self._save_csv_with_retry(csv_filename, df)
                return csv_filename
            else:
                print("No data found for CSV report")
                return ""
                
        except Exception as e:
            print(f"❌ Error generating CSV report: {e}")
            return ""

    @retry_file_operation(max_retries=3, delay=1)
    def _save_csv_with_retry(self, filename: str, df: pd.DataFrame):
        """Save CSV with retry logic."""
        df.to_csv(filename, index=False)
        print(f"✅ CSV report generated: {filename}")

    def get_report_summary(self) -> Dict[str, Any]:
        """
        Get a summary of today's findings for quick review.
        """
        today_str = date.today().isoformat()
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Get basic counts
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM findings WHERE date_found LIKE ?", (f"{today_str}%",))
                total_findings = cursor.fetchone()[0]
                
                # Get event type breakdown
                cursor.execute("""
                    SELECT event_type, COUNT(*) 
                    FROM findings 
                    WHERE date_found LIKE ? 
                    GROUP BY event_type
                """, (f"{today_str}%",))
                event_breakdown = dict(cursor.fetchall())
                
                # Get total value
                cursor.execute("""
                    SELECT SUM(value_usd) 
                    FROM findings 
                    WHERE date_found LIKE ? AND value_usd > 0
                """, (f"{today_str}%",))
                total_value = cursor.fetchone()[0] or 0
                
                return {
                    'date': today_str,
                    'total_findings': total_findings,
                    'event_breakdown': event_breakdown,
                    'total_value': total_value
                }
                
        except Exception as e:
            print(f"❌ Error getting report summary: {e}")
            return {} 