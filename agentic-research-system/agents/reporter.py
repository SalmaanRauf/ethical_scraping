import sqlite3
import pandas as pd
import time
from datetime import date, datetime
from typing import List, Dict, Any
import os
from functools import wraps

def retry_file_operation(max_retries=3, delay=1):
    """Decorator for retrying file operations with exponential backoff."""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except IOError as e:
                    if attempt == max_retries - 1:
                        print(f"❌ File operation failed after {max_retries} attempts: {e}")
                        raise
                    print(f"⚠️  File operation failed (attempt {attempt + 1}/{max_retries}): {e}")
                    time.sleep(delay * (2 ** attempt))  # Exponential backoff
            return None
        return wrapper
    return decorator

class Reporter:
    def __init__(self, db_path='data/research.db'):
        self.db_path = db_path
        self.max_results_per_query = 1000  # Limit results to prevent memory issues
        # Ensure reports directory exists
        os.makedirs('reports', exist_ok=True)

    def _get_paginated_results(self, query: str, params: tuple, page_size: int = 100) -> pd.DataFrame:
        """Get results in pages to prevent memory issues with large datasets."""
        all_results = []
        offset = 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                while True:
                    # Add LIMIT and OFFSET to query
                    paginated_query = f"{query} LIMIT {page_size} OFFSET {offset}"
                    
                    df_page = pd.read_sql_query(paginated_query, conn, params=params)
                    
                    if df_page.empty:
                        break
                    
                    all_results.append(df_page)
                    offset += page_size
                    
                    # Safety check to prevent infinite loops
                    if len(all_results) * page_size > self.max_results_per_query:
                        print(f"⚠️  Reached maximum results limit ({self.max_results_per_query})")
                        break
                
                # Combine all pages
                if all_results:
                    return pd.concat(all_results, ignore_index=True)
                else:
                    return pd.DataFrame()
                    
        except Exception as e:
            print(f"❌ Error in paginated query: {e}")
            return pd.DataFrame()

    def generate_report(self) -> str:
        """
        Queries DB for today's findings and generates a report.
        """
        today_str = date.today().isoformat()
        
        try:
            # Query for findings found today using pagination
            query = """
                SELECT 
                    date_found, company, headline, what_happened, 
                    why_it_matters, consulting_angle, source_url, 
                    event_type, value_usd, source_type
                FROM findings 
                WHERE date_found LIKE ?
                ORDER BY created_at DESC
            """
            
            df = self._get_paginated_results(query, (f"{today_str}%",))
            
            if df.empty:
                report_content = "# Daily Intelligence Report\n\n"
                report_content += f"**Date:** {today_str}\n\n"
                report_content += "## Summary\n\n"
                report_content += "No material updates found today.\n\n"
                report_content += "---\n"
                report_content += "*Report generated by Agentic Account Research System*"
            else:
                # Add Key Person columns as per requirements
                df['Key Person 1 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                df['Key Person 2 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                
                # Rename columns to match final schema
                df.rename(columns={
                    'date_found': 'Date', 
                    'company': 'Company', 
                    'headline': 'Headline', 
                    'what_happened': 'What Happened?', 
                    'why_it_matters': 'Why it Matters', 
                    'consulting_angle': 'Consulting Angle', 
                    'source_url': 'Source 1 (URL)',
                    'event_type': 'Event Type',
                    'value_usd': 'Value (USD)'
                }, inplace=True)
                
                # Reorder columns to match required output schema
                column_order = [
                    'Date', 'Company', 'Headline', 'What Happened?', 
                    'Why it Matters', 'Consulting Angle', 'Source 1 (URL)',
                    'Key Person 1 (URL, Role, Score)', 'Key Person 2 (URL, Role, Score)',
                    'Event Type', 'Value (USD)'
                ]
                
                # Only include columns that exist in the dataframe
                existing_columns = [col for col in column_order if col in df.columns]
                df = df[existing_columns]
                
                # Generate markdown report
                report_content = "# Daily Intelligence Report\n\n"
                report_content += f"**Date:** {today_str}\n\n"
                report_content += f"**Total Events Found:** {len(df)}\n\n"
                report_content += "## Summary\n\n"
                
                # Add summary statistics
                if 'Event Type' in df.columns:
                    event_counts = df['Event Type'].value_counts()
                    report_content += "**Events by Type:**\n"
                    for event_type, count in event_counts.items():
                        report_content += f"- {event_type}: {count}\n"
                    report_content += "\n"
                
                if 'Value (USD)' in df.columns:
                    total_value = df['Value (USD)'].sum()
                    if total_value > 0:
                        report_content += f"**Total Value:** ${total_value:,}\n\n"
                
                report_content += "## Detailed Findings\n\n"
                report_content += df.to_markdown(index=False)
                report_content += "\n\n---\n"
                report_content += "*Report generated by Agentic Account Research System*"

        except Exception as e:
            print(f"❌ Error generating report: {e}")
            report_content = f"# Error Generating Report\n\nError: {e}"

        # Save report to a file with retry logic
        report_filename = f"reports/report-{today_str}.md"
        self._save_report_with_retry(report_filename, report_content)

        return report_content

    @retry_file_operation(max_retries=3, delay=1)
    def _save_report_with_retry(self, filename: str, content: str):
        """Save report with retry logic."""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"✅ Report generated: {filename}")

    def generate_csv_report(self) -> str:
        """
        Generate a CSV version of today's report.
        """
        today_str = date.today().isoformat()
        
        try:
            # Query for findings found today using pagination
            query = """
                SELECT 
                    date_found, company, headline, what_happened, 
                    why_it_matters, consulting_angle, source_url, 
                    event_type, value_usd, source_type
                FROM findings 
                WHERE date_found LIKE ?
                ORDER BY created_at DESC
            """
            
            df = self._get_paginated_results(query, (f"{today_str}%",))
            
            if not df.empty:
                # Add Key Person columns
                df['Key Person 1 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                df['Key Person 2 (URL, Role, Score)'] = "N/A - Manual Lookup Required"
                
                # Rename columns
                df.rename(columns={
                    'date_found': 'Date', 
                    'company': 'Company', 
                    'headline': 'Headline', 
                    'what_happened': 'What Happened?', 
                    'why_it_matters': 'Why it Matters', 
                    'consulting_angle': 'Consulting Angle', 
                    'source_url': 'Source 1 (URL)',
                    'event_type': 'Event Type',
                    'value_usd': 'Value (USD)'
                }, inplace=True)
                
                # Save CSV with retry logic
                csv_filename = f"reports/report-{today_str}.csv"
                self._save_csv_with_retry(csv_filename, df)
                return csv_filename
            else:
                print("No data found for CSV report")
                return ""
                
        except Exception as e:
            print(f"❌ Error generating CSV report: {e}")
            return ""

    @retry_file_operation(max_retries=3, delay=1)
    def _save_csv_with_retry(self, filename: str, df: pd.DataFrame):
        """Save CSV with retry logic."""
        df.to_csv(filename, index=False)
        print(f"✅ CSV report generated: {filename}")

    def get_report_summary(self) -> Dict[str, Any]:
        """
        Get a summary of today's findings for quick review.
        """
        today_str = date.today().isoformat()
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Get basic counts
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM findings WHERE date_found LIKE ?", (f"{today_str}%",))
                total_findings = cursor.fetchone()[0]
                
                # Get event type breakdown
                cursor.execute("""
                    SELECT event_type, COUNT(*) 
                    FROM findings 
                    WHERE date_found LIKE ? 
                    GROUP BY event_type
                """, (f"{today_str}%",))
                event_breakdown = dict(cursor.fetchall())
                
                # Get total value
                cursor.execute("""
                    SELECT SUM(value_usd) 
                    FROM findings 
                    WHERE date_found LIKE ? AND value_usd > 0
                """, (f"{today_str}%",))
                total_value = cursor.fetchone()[0] or 0
                
                return {
                    'date': today_str,
                    'total_findings': total_findings,
                    'event_breakdown': event_breakdown,
                    'total_value': total_value
                }
                
        except Exception as e:
            print(f"❌ Error getting report summary: {e}")
            return {} 

def format_company_briefing(self, analysis_result: List[Dict], company_slug: str) -> Dict:
    """
    Format analysis results into a comprehensive company briefing.
    
    Args:
        analysis_result: List of analyzed events
        company_slug: Canonical company slug
        
    Returns:
        Dictionary containing formatted briefing
    """
    try:
        # Get company display name
        from config.company_config import COMPANY_DISPLAY_NAMES
        display_name = COMPANY_DISPLAY_NAMES.get(company_slug, company_slug)
        
        # Format briefing content
        briefing_content = self._create_briefing_content(analysis_result, display_name)
        
        return {
            'company_name': display_name,
            'company_slug': company_slug,
            'briefing': briefing_content,
            'status': 'success',
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"Error formatting briefing: {e}")
        return {
            'error': str(e),
            'company_slug': company_slug,
            'status': 'failed'
        }
    
    def _create_briefing_content(self, analysis_result: List[Dict], company_name: str) -> str:
        """Create formatted briefing content with all required fields."""
        
        if not analysis_result:
            return (f"📊 **{company_name} Intelligence Briefing**\n\n"
                   f"No significant events or findings were detected in the recent data. "
                   f"This could indicate a period of relative stability or limited recent activity.")
        
        # Group events by type
        events_by_type = {}
        for event in analysis_result:
            event_type = event.get('event_type', 'Other')
            if event_type not in events_by_type:
                events_by_type[event_type] = []
            events_by_type[event_type].append(event)
        
        # Create briefing sections
        sections = []
        
        # Executive Summary
        summary = self._create_executive_summary(analysis_result, company_name)
        sections.append(summary)
        
        # Key Events by Category with All Required Fields
        for event_type, events in events_by_type.items():
            section = self._create_event_section_with_all_fields(event_type, events)
            sections.append(section)
        
        # Consulting Opportunities
        opportunities = self._create_consulting_opportunities(analysis_result)
        sections.append(opportunities)
        
        # Industry Overview
        industry_overview = self._create_industry_overview_section(analysis_result)
        sections.append(industry_overview)
        
        # Company Profile Snippets
        profile_snippets = self._create_company_profile_snippets(analysis_result)
        sections.append(profile_snippets)
        
        # Sources
        sources = self._create_sources_section(analysis_result)
        sections.append(sources)
        
        return "\n\n".join(sections)
    
    def _create_executive_summary(self, analysis_result: List[Dict], company_name: str) -> str:
        """Create executive summary section."""
        total_events = len(analysis_result)
        high_priority = len([e for e in analysis_result if e.get('priority') == 'high'])
        
        summary = f"📊 **{company_name} Intelligence Briefing**\n\n"
        summary += f"**Executive Summary**\n"
        summary += f"• Total Events Analyzed: {total_events}\n"
        summary += f"• High Priority Events: {high_priority}\n"
        summary += f"• Analysis Period: Last 30 days\n\n"
        
        return summary
    
    def _create_event_section(self, event_type: str, events: List[Dict]) -> str:
        """Create section for specific event type."""
        section = f"**{event_type.upper()} EVENTS**\n\n"
        
        for event in events:
            title = event.get('title', 'Unknown Event')
            what_happened = event.get('insights', {}).get('what_happened', '')
            why_matters = event.get('insights', {}).get('why_it_matters', '')
            consulting_angle = event.get('insights', {}).get('consulting_angle', '')
            
            section += f"**{title}**\n"
            if what_happened:
                section += f"• What Happened: {what_happened}\n"
            if why_matters:
                section += f"• Why It Matters: {why_matters}\n"
            if consulting_angle:
                section += f"• Consulting Opportunity: {consulting_angle}\n"
            section += "\n"
        
        return section
    
    def _create_consulting_opportunities(self, analysis_result: List[Dict]) -> str:
        """Create consulting opportunities section."""
        opportunities = []
        
        for event in analysis_result:
            consulting_angle = event.get('insights', {}).get('consulting_angle', '')
            if consulting_angle:
                opportunities.append(consulting_angle)
        
        if not opportunities:
            return ""
        
        section = "**CONSULTING OPPORTUNITIES**\n\n"
        for i, opportunity in enumerate(opportunities[:5], 1):  # Limit to top 5
            section += f"{i}. {opportunity}\n"
        
        return section
    
    def _create_sources_section(self, analysis_result: List[Dict]) -> str:
        """Create sources section."""
        sources = set()
        
        for event in analysis_result:
            source_url = event.get('source_url') or event.get('url') or event.get('link')
            if source_url:
                sources.add(source_url)
        
        if not sources:
            return ""
        
        section = "**SOURCES**\n\n"
        for source in list(sources)[:10]:  # Limit to top 10
            section += f"• {source}\n"
        
        return section 

    def _create_event_section_with_all_fields(self, event_type: str, events: List[Dict]) -> str:
        """Create section for specific event type with all required fields."""
        section = f"**{event_type.upper()} EVENTS**\n\n"
        
        for event in events:
            title = event.get('title', 'Unknown Event')
            insights = event.get('insights', {})
            
            # Extract all required fields
            what_happened = insights.get('what_happened', '')
            why_matters = insights.get('why_it_matters', '')
            consulting_angle = insights.get('consulting_angle', '')
            need_type = insights.get('need_type', '')
            service_line = insights.get('service_line', '')
            urgency = insights.get('urgency', '')
            industry_overview = insights.get('industry_overview', '')
            
            section += f"**{title}**\n"
            
            if what_happened:
                section += f"• **What Happened:** {what_happened}\n"
            
            if why_matters:
                section += f"• **Why It Matters:** {why_matters}\n"
            
            if consulting_angle:
                section += f"• **Consulting Angle:** {consulting_angle}\n"
            
            if need_type:
                section += f"• **Need Type:** {need_type.title()}\n"
            
            if service_line:
                section += f"• **Service Line:** {service_line}\n"
            
            if urgency:
                section += f"• **Urgency:** {urgency}\n"
            
            if industry_overview:
                section += f"• **Industry Context:** {industry_overview}\n"
            
            # Add source information
            url = event.get('url', '')
            if url:
                section += f"• **Source:** {url}\n"
            
            section += "\n---\n\n"
        
        return section
    
    def _create_industry_overview_section(self, analysis_result: List[Dict]) -> str:
        """Create industry overview section from Bing data and analysis."""
        section = "**INDUSTRY OVERVIEW**\n\n"
        
        # Collect industry insights from all events
        industry_insights = []
        for event in analysis_result:
            insights = event.get('insights', {})
            industry_overview = insights.get('industry_overview', '')
            if industry_overview:
                industry_insights.append(industry_overview)
        
        if industry_insights:
            # Deduplicate and summarize industry insights
            unique_insights = list(set(industry_insights))
            for insight in unique_insights[:5]:  # Limit to top 5 insights
                section += f"• {insight}\n"
        else:
            section += "• Industry context analysis pending additional data\n"
        
        return section
    
    def _create_company_profile_snippets(self, analysis_result: List[Dict]) -> str:
        """Create company profile snippets section."""
        section = "**COMPANY PROFILE SNIPPETS**\n\n"
        
        # Extract profile data from events
        active_opportunities = []
        key_buyers = []
        alumni_contacts = []
        
        for event in analysis_result:
            company_profile = event.get('company_profile', {})
            
            # Extract opportunities
            if 'opportunities' in company_profile:
                active_opportunities.extend(company_profile['opportunities'])
            
            # Extract key buyers
            if 'key_buyers' in company_profile:
                key_buyers.extend(company_profile['key_buyers'])
            
            # Extract alumni contacts
            if 'alumni_contacts' in company_profile:
                alumni_contacts.extend(company_profile['alumni_contacts'])
        
        # Format sections
        if active_opportunities:
            section += "**Active Opportunities:**\n"
            for opp in active_opportunities[:3]:  # Limit to top 3
                section += f"• {opp}\n"
            section += "\n"
        
        if key_buyers:
            section += "**Key Buyers:**\n"
            for buyer in key_buyers[:3]:  # Limit to top 3
                section += f"• {buyer}\n"
            section += "\n"
        
        if alumni_contacts:
            section += "**Alumni Contacts:**\n"
            for contact in alumni_contacts[:3]:  # Limit to top 3
                section += f"• {contact}\n"
            section += "\n"
        
        if not any([active_opportunities, key_buyers, alumni_contacts]):
            section += "• Company profile data not available\n"
        
        return section 